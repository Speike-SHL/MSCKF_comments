The {\ttfamily M\+S\+C\+K\+F\+\_\+\+V\+IO} package is a stereo version of M\+S\+C\+KF. The software takes in synchronized stereo images and I\+MU messages and generates real-\/time 6D\+OF pose estimation of the I\+MU frame.

The software is tested on Ubuntu 16.\+04 with R\+OS Kinetic.

Video\+: \href{https://www.youtube.com/watch?v=jxfJFgzmNSw&t=3s}{\texttt{ https\+://www.\+youtube.\+com/watch?v=jxf\+J\+Fgzm\+N\+Sw\&t}}~\newline
 Paper Draft\+: \href{https://arxiv.org/abs/1712.00036}{\texttt{ https\+://arxiv.\+org/abs/1712.\+00036}}\hypertarget{md__r_e_a_d_m_e_autotoc_md1}{}\doxysection{License}\label{md__r_e_a_d_m_e_autotoc_md1}
Penn Software License. See \mbox{\hyperlink{_l_i_c_e_n_s_e_8txt}{L\+I\+C\+E\+N\+S\+E.\+txt}} for further details.\hypertarget{md__r_e_a_d_m_e_autotoc_md2}{}\doxysection{Dependencies}\label{md__r_e_a_d_m_e_autotoc_md2}
Most of the dependencies are standard including {\ttfamily Eigen}, {\ttfamily Open\+CV}, and {\ttfamily Boost}. The standard shipment from Ubuntu 16.\+04 and R\+OS Kinetic works fine. One special requirement is {\ttfamily suitesparse}, which can be installed through,


\begin{DoxyCode}{0}
\DoxyCodeLine{sudo apt-\/get install libsuitesparse-\/dev}
\end{DoxyCode}
\hypertarget{md__r_e_a_d_m_e_autotoc_md3}{}\doxysection{Compling}\label{md__r_e_a_d_m_e_autotoc_md3}
The software is a standard catkin package. Make sure the package is on {\ttfamily R\+O\+S\+\_\+\+P\+A\+C\+K\+A\+G\+E\+\_\+\+P\+A\+TH} after cloning the package to your workspace. And the normal procedure for compiling a catkin package should work.


\begin{DoxyCode}{0}
\DoxyCodeLine{cd your\_work\_space}
\DoxyCodeLine{catkin\_make -\/-\/pkg msckf\_vio -\/-\/cmake-\/args -\/DCMAKE\_BUILD\_TYPE=Release}
\end{DoxyCode}
\hypertarget{md__r_e_a_d_m_e_autotoc_md4}{}\doxysection{Calibration}\label{md__r_e_a_d_m_e_autotoc_md4}
An accurate calibration is crucial for successfully running the software. To get the best performance of the software, the stereo cameras and I\+MU should be hardware synchronized. Note that for the stereo calibration, which includes the camera intrinsics, distortion, and extrinsics between the two cameras, you have to use a calibration software. {\bfseries{Manually setting these parameters will not be accurate enough.}} \href{https://github.com/ethz-asl/kalibr}{\texttt{ Kalibr}} can be used for the stereo calibration and also to get the transformation between the stereo cameras and I\+MU. The yaml file generated by Kalibr can be directly used in this software. See calibration files in the {\ttfamily config} folder for details. The two calibration files in the {\ttfamily config} folder should work directly with the Eu\+RoC and \href{https://github.com/KumarRobotics/msckf_vio/wiki}{\texttt{ fast flight}} datasets. The convention of the calibration file is as follows\+:

{\ttfamily camx/\+T\+\_\+cam\+\_\+imu}\+: takes a vector from the I\+MU frame to the camx frame. {\ttfamily cam1/\+T\+\_\+cn\+\_\+cnm1}\+: takes a vector from the cam0 frame to the cam1 frame.

The filter uses the first 200 I\+MU messages to initialize the gyro bias, acc bias, and initial orientation. Therefore, the robot is required to start from a stationary state in order to initialize the V\+IO successfully.\hypertarget{md__r_e_a_d_m_e_autotoc_md5}{}\doxysection{Eu\+Ro\+C and U\+Penn Fast flight dataset example usage}\label{md__r_e_a_d_m_e_autotoc_md5}
First obtain either the \href{https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets}{\texttt{ Eu\+RoC}} or the \href{https://github.com/KumarRobotics/msckf_vio/wiki/Dataset}{\texttt{ U\+Penn fast flight}} dataset.

Recommended Eu\+RoC R\+OS Bags\+:
\begin{DoxyItemize}
\item \href{http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.bag}{\texttt{ Vicon Room 1 01}}
\item \href{http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_easy/V1_02_easy.bag}{\texttt{ Vicon Room 1 02}}
\end{DoxyItemize}

Once the {\ttfamily \mbox{\hyperlink{namespacemsckf__vio}{msckf\+\_\+vio}}} is built and sourced (via {\ttfamily source $<$path to catkin\+\_\+ws$>$/devel/setup.bash}), there are two launch files prepared for the \href{https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets}{\texttt{ Eu\+RoC}} and \href{https://github.com/KumarRobotics/msckf_vio/wiki/Dataset}{\texttt{ U\+Penn fast flight}} dataset named {\ttfamily msckf\+\_\+vio\+\_\+euroc.\+launch} and {\ttfamily msckf\+\_\+vio\+\_\+fla.\+launch} respectively. Each launch files instantiates two R\+OS nodes\+:


\begin{DoxyItemize}
\item {\ttfamily image\+\_\+processor} processes stereo images to detect and track features
\item {\ttfamily vio} obtains feature measurements from the {\ttfamily image\+\_\+processor} and tightly fuses them with the I\+MU messages to estimate pose.
\end{DoxyItemize}

These launch files can be executed via


\begin{DoxyCode}{0}
\DoxyCodeLine{roslaunch msckf\_vio msckf\_vio\_euroc.launch}
\end{DoxyCode}


or


\begin{DoxyCode}{0}
\DoxyCodeLine{roslaunch msckf\_vio msckf\_vio\_fla.launch}
\end{DoxyCode}


Once the nodes are running you need to run the dataset rosbags (in a different terminal), for example\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{rosbag play V1\_01\_easy.bag}
\end{DoxyCode}


As mentioned in the previous section, {\bfseries{The robot is required to start from a stationary state in order to initialize the V\+IO successfully.}}

To visualize the pose and feature estimates you can use the provided rviz configurations found in {\ttfamily msckf\+\_\+vio/rviz} folder (Eu\+RoC\+: {\ttfamily rviz\+\_\+euroc\+\_\+config.\+rviz}, Fast dataset\+: {\ttfamily rviz\+\_\+fla\+\_\+config.\+rviz}).\hypertarget{md__r_e_a_d_m_e_autotoc_md6}{}\doxysection{R\+O\+S Nodes}\label{md__r_e_a_d_m_e_autotoc_md6}
\hypertarget{md__r_e_a_d_m_e_autotoc_md7}{}\doxysubsection{$<$tt$>$image\+\_\+processor$<$/tt$>$ node}\label{md__r_e_a_d_m_e_autotoc_md7}
{\bfseries{Subscribed Topics}}

{\ttfamily imu} ({\ttfamily sensor\+\_\+msgs/\+Imu})

I\+MU messages is used for compensating rotation in feature tracking, and 2-\/point R\+A\+N\+S\+AC.

{\ttfamily cam\mbox{[}x\mbox{]}\+\_\+image} ({\ttfamily sensor\+\_\+msgs/\+Image})

Synchronized stereo images.

{\bfseries{Published Topics}}

{\ttfamily features} ({\ttfamily msckf\+\_\+vio/\+Camera\+Measurement})

Records the feature measurements on the current stereo image pair.

{\ttfamily tracking\+\_\+info} ({\ttfamily msckf\+\_\+vio/\+Tracking\+Info})

Records the feature tracking status for debugging purpose.

{\ttfamily debug\+\_\+stereo\+\_\+img} ({\ttfamily sensor\+\_\+msgs\+::\+Image})

Draw current features on the stereo images for debugging purpose. Note that this debugging image is only generated upon subscription.\hypertarget{md__r_e_a_d_m_e_autotoc_md8}{}\doxysubsection{$<$tt$>$vio$<$/tt$>$ node}\label{md__r_e_a_d_m_e_autotoc_md8}
{\bfseries{Subscribed Topics}}

{\ttfamily imu} ({\ttfamily sensor\+\_\+msgs/\+Imu})

I\+MU measurements.

{\ttfamily features} ({\ttfamily msckf\+\_\+vio/\+Camera\+Measurement})

Stereo feature measurements from the {\ttfamily image\+\_\+processor} node.

{\bfseries{Published Topics}}

{\ttfamily odom} ({\ttfamily nav\+\_\+msgs/\+Odometry})

Odometry of the I\+MU frame including a proper covariance.

{\ttfamily feature\+\_\+point\+\_\+cloud} ({\ttfamily sensor\+\_\+msgs/\+Point\+Cloud2})

Shows current features in the map which is used for estimation. 